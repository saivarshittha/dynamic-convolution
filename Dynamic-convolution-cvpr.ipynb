{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os \n",
    "import pandas as pd\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from collections import OrderedDict\n",
    "from torchvision.models.resnet import resnet18 as raw_resnet18\n",
    "# from dynamic_models.dy_resnet import resnet18 as dy_resnet18\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
    "           'wide_resnet50_2', 'wide_resnet101_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention1d(nn.Module):\n",
    "    def __init__(self,in_planes,ratios,K,temperature,init_weight = True):\n",
    "        super(attention1d,self).__init__()\n",
    "        assert temperature % 3 == 1 # for reducing τ temperature from 30 to 1 linearly in the first 10 epochs.\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        if in_planes != 3:\n",
    "            hidden_planes = int(in_planes * ratios) + 1\n",
    "        else:\n",
    "            hidden_planes = K\n",
    "        \n",
    "        self.fc1   = nn.Conv1d(in_planes,hidden_planes,1,bias = False)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.fc2   = nn.Conv1d(hidden_planes,K,1,bias = True)\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            \n",
    "            if isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "    \n",
    "    def update__temperature(self):\n",
    "        if self.temperature != 1:\n",
    "            self.temperature -= 3\n",
    "    \n",
    "    def forward(self,z):\n",
    "        z = self.avgpool(z)\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.fc2(z)\n",
    "        z = z.view(z.size(0),-1)   \n",
    "        return F.softmax(z/self.temperature,1) \n",
    "    \n",
    "class Dynamic_conv1d(nn.Module):\n",
    "    def __init__(self,in_planes,out_planes,kernel_size,ratio = 0.25,stride = 1,padding = 0,dilation = 1,groups = 1,bias = True,K = 4,temperature = 34,init_weight = True):\n",
    "        super(Dynamic_conv1d,self).__init__()\n",
    "        \n",
    "        if in_planes%groups != 0:\n",
    "            raise ValueError('Error : in_planes%groups != 0')\n",
    "        self.in_planes    = in_planes\n",
    "        self.out_planes   = out_planes\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.stride       = stride\n",
    "        self.padding      = padding\n",
    "        self.dilation     = dilation\n",
    "        self.groups       = groups\n",
    "        self.bias         = bias\n",
    "        self.K            = K\n",
    "        self.attention    = attention1d(in_planes,ratio,K,temperature)\n",
    "        self.weight       = nn.Parameter(torch.randn(K,out_planes,in_planes//groups,kernel_size),requires_grad = True)\n",
    "        \n",
    "        if bias :\n",
    "            self.bias = nn.Parameter(torch.Tensor(K,out_planes))\n",
    "        else:\n",
    "            self.bias = None\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for i in range(self.K):\n",
    "            nn.init.kaiming_uniform_(self.weight[i])\n",
    "    def update_temperature(self):\n",
    "        self.attention.update__temperature()\n",
    "    \n",
    "    def forward(self,z):\n",
    "        \n",
    "#         Regard batch as a dimensional variable, perform group convolution,\n",
    "#         because the weight of group convolution is different, \n",
    "#         and the weight of dynamic convolution is also different\n",
    "        softmax_attention = self.attention(z)\n",
    "        batch_size ,in_planes,height = z.size()\n",
    "        z = z.view(1,-1,height,) # changing into dimension for group convolution\n",
    "        weight = self.weight.view(self.K,-1)\n",
    "        \n",
    "#         The generation of the weight of dynamic convolution,\n",
    "#         which generates batch_size convolution parameters \n",
    "#         (each parameter is different) \n",
    "        aggregate_weight = torch.mm(softmax_attention,self.bias).view(-1,self.in_planes,self.kernel_size,)# expects two matrices (2D tensors)\n",
    "        if self.bias is not None:\n",
    "            aggregate_bias = torch.mm(softmax_attention,self.bias).view(-1)\n",
    "            output = F.conv1d(x,weight = aggregate_weight,bias = aggregate_bias,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        else:\n",
    "            output = F.conv1d(x,weight = aggregate_weight,bias = None,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        output = output.view(batch_size, self.out_planes, output.size(-1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention2d(nn.Module):\n",
    "    def __init__(self,in_planes,ratios,K,temperature,init_weight = True):\n",
    "        super(attention2d,self).__init__()\n",
    "        assert temperature % 3 == 1 # for reducing τ temperature from 30 to 1 linearly in the first 10 epochs.\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        if in_planes != 3:\n",
    "            hidden_planes = int(in_planes * ratios) + 1\n",
    "        else:\n",
    "            hidden_planes = K\n",
    "        \n",
    "        self.fc1   = nn.Conv2d(in_planes,hidden_planes,1,bias = False)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.fc2   = nn.Conv2d(hidden_planes,K,1,bias = True)\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            \n",
    "            if isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "    \n",
    "    def update__temperature(self):\n",
    "        if self.temperature != 1:\n",
    "            self.temperature -= 3\n",
    "    \n",
    "    def forward(self,z):\n",
    "        z = self.avgpool(z)\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.fc2(z)\n",
    "        z = z.view(z.size(0),-1)   \n",
    "        return F.softmax(z/self.temperature,1) \n",
    "    \n",
    "class Dynamic_conv2d(nn.Module):\n",
    "    def __init__(self,in_planes,out_planes,kernel_size,ratio = 0.25,stride = 1,padding = 0,dilation = 1,groups = 1,bias = True,K = 4,temperature = 34,init_weight = True):\n",
    "        super(Dynamic_conv2d,self).__init__()\n",
    "        \n",
    "        if in_planes%groups != 0:\n",
    "            raise ValueError('Error : in_planes%groups != 0')\n",
    "        self.in_planes    = in_planes\n",
    "        self.out_planes   = out_planes\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.stride       = stride\n",
    "        self.padding      = padding\n",
    "        self.dilation     = dilation\n",
    "        self.groups       = groups\n",
    "        self.bias         = bias\n",
    "        self.K            = K\n",
    "        self.attention    = attention2d(in_planes,ratio,K,temperature)\n",
    "        self.weight       = nn.Parameter(torch.randn(K,out_planes,in_planes//groups,kernel_size,kernel_size),requires_grad = True)\n",
    "        \n",
    "        if bias :\n",
    "            self.bias = nn.Parameter(torch.Tensor(K,out_planes))\n",
    "        else:\n",
    "            self.bias = None\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for i in range(self.K):\n",
    "            nn.init.kaiming_uniform_(self.weight[i])\n",
    "    def update_temperature(self):\n",
    "        self.attention.update__temperature()\n",
    "    \n",
    "    def forward(self,z):\n",
    "        \n",
    "#         Regard batch as a dimensional variable, perform group convolution,\n",
    "#         because the weight of group convolution is different, \n",
    "#         and the weight of dynamic convolution is also different\n",
    "        softmax_attention = self.attention(z)\n",
    "        batch_size ,in_planes,height,width = z.size()\n",
    "        z = z.view(1,-1,height,width) # changing into dimension for group convolution\n",
    "        weight = self.weight.view(self.K,-1)\n",
    "        \n",
    "#         The generation of the weight of dynamic convolution,\n",
    "#         which generates batch_size convolution parameters \n",
    "#         (each parameter is different) \n",
    "        aggregate_weight = torch.mm(softmax_attention,self.bias).view(-1,self.in_planes,self.kernel_size,)# expects two matrices (2D tensors)\n",
    "        if self.bias is not None:\n",
    "            aggregate_bias = torch.mm(softmax_attention,self.bias).view(-1)\n",
    "            output = F.conv2d(x,weight = aggregate_weight,bias = aggregate_bias,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        else:\n",
    "            output = F.conv2d(x,weight = aggregate_weight,bias = None,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        output = output.view(batch_size, self.out_planes, output.size(-2),output.size(-1))\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention3d(nn.Module):\n",
    "    def __init__(self,in_planes,ratios,K,temperature,init_weight = True):\n",
    "        super(attention3d,self).__init__()\n",
    "        assert temperature % 3 == 1 # for reducing τ temperature from 30 to 1 linearly in the first 10 epochs.\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "        \n",
    "        if in_planes != 3:\n",
    "            hidden_planes = int(in_planes * ratios) + 1\n",
    "        else:\n",
    "            hidden_planes = K\n",
    "        \n",
    "        self.fc1   = nn.Conv3d(in_planes,hidden_planes,1,bias = False)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.fc2   = nn.Conv3d(hidden_planes,K,1,bias = False)\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            \n",
    "            if isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "    \n",
    "    def update__temperature(self):\n",
    "        if self.temperature != 1:\n",
    "            self.temperature -= 3\n",
    "    \n",
    "    def forward(self,z):\n",
    "        z = self.avgpool(z)\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.fc2(z)\n",
    "        z = z.view(z.size(0),-1)   \n",
    "        return F.softmax(z/self.temperature,1) \n",
    "    \n",
    "class Dynamic_conv3d(nn.Module):\n",
    "    def __init__(self,in_planes,out_planes,kernel_size,ratio = 0.25,stride = 1,padding = 0,dilation = 1,groups = 1,bias = True,K = 4,temperature = 34,init_weight = True):\n",
    "        super(Dynamic_conv2d,self).__init__()\n",
    "        \n",
    "        if in_planes%groups != 0:\n",
    "            raise ValueError('Error : in_planes%groups != 0')\n",
    "        self.in_planes    = in_planes\n",
    "        self.out_planes   = out_planes\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.stride       = stride\n",
    "        self.padding      = padding\n",
    "        self.dilation     = dilation\n",
    "        self.groups       = groups\n",
    "        self.bias         = bias\n",
    "        self.K            = K\n",
    "        self.attention    = attention3d(in_planes,ratio,K,temperature)\n",
    "        self.weight       = nn.Parameter(torch.randn(K,out_planes,in_planes//groups,kernel_size,kernel_size),requires_grad = True)\n",
    "        \n",
    "        if bias :\n",
    "            self.bias = nn.Parameter(torch.Tensor(K,out_planes))\n",
    "        else:\n",
    "            self.bias = None\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for i in range(self.K):\n",
    "            nn.init.kaiming_uniform_(self.weight[i])\n",
    "    def update_temperature(self):\n",
    "        self.attention.update__temperature()\n",
    "    \n",
    "    def forward(self,z):\n",
    "        \n",
    "#         Regard batch as a dimensional variable, perform group convolution,\n",
    "#         because the weight of group convolution is different, \n",
    "#         and the weight of dynamic convolution is also different\n",
    "        softmax_attention = self.attention(z)\n",
    "        batch_size ,in_planes,height,width = z.size()\n",
    "        z = z.view(1,-1,height,width) # changing into dimension for group convolution\n",
    "        weight = self.weight.view(self.K,-1)\n",
    "        \n",
    "#         The generation of the weight of dynamic convolution,\n",
    "#         which generates batch_size convolution parameters \n",
    "#         (each parameter is different) \n",
    "        aggregate_weight = torch.mm(softmax_attention,self.bias).view(-1,self.in_planes,self.kernel_size,self.kernel_size,self.kernel_size)# expects two matrices (2D tensors)\n",
    "        if self.bias is not None:\n",
    "            aggregate_bias = torch.mm(softmax_attention,self.bias).view(-1)\n",
    "            output = F.conv3d(x,weight = aggregate_weight,bias = aggregate_bias,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        else:\n",
    "            output = F.conv3d(x,weight = aggregate_weight,bias = None,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        output = output.view(batch_size, self.out_planes,output.size(-3),output.size(-2),output.size(-1))\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.8743e+31]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dy_resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### conv1x1 - dynamic convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_planes,out_planes,stride = 1): \n",
    "    return Dynamic_conv2d(in_planes,out_planes,kernel_size = 1,stride = stride,bias = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### conv3x3 - dynamic convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes,out_planes,stride = 1,groups = 1,dilation = 1): # conv3x3 for dynamic convolution\n",
    "    return Dynamic_conv2d(in_planes,out_planes,kernel_size = 3,stride = stride,padding = dilation,groups = groups,bias = False,dilation = dilation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module): # expansion = 1, dilation = 1 , base_width = 64 ,groups = 1\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self,in_planes,out_planes,stride = 1,downsample = None,\n",
    "                 groups = 1,base_width = 64,dilation = 1,norm_layer = None):\n",
    "        \n",
    "        super(BasicBlock,self).__init__()\n",
    "        \n",
    "        if base_width != 64:\n",
    "            raise ValueError('BasicBlock supports only base_width = 64')\n",
    "        if groups != 1: \n",
    "            raise ValueError('BasicBlock supports only groups = 1')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError('BasicBlock doesnot support dilation > 1')\n",
    "        # self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        \n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        \n",
    "        self.conv1 = conv3x3(in_planes,out_planes,stride)\n",
    "        self.bn1   = norm_layer(out_planes)\n",
    "        self.relu  = nn.ReLU() # modify input directly.\n",
    "        self.conv2 = conv3x3(out_planes,out_planes)\n",
    "        self.bn2   = norm_layer(out_planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self , z):\n",
    "        \n",
    "        identity = z\n",
    "        \n",
    "        out = self.conv1(z)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(z)\n",
    "        \n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self,in_planes,out_planes,stride = 1,downsample = None,\n",
    "                groups = 1,base_width = 64,dilation = 1,norm_layer = None):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        \n",
    "        width = int(out_planes *(base_width/64.)) * groups  ## ?? \n",
    "        \n",
    "        self.conv1  = conv1x1(in_planes,width)\n",
    "        self.bn1    = norm_layer(width)\n",
    "        self.conv2  = conv3x3(width,width,stride,groups,dilation)\n",
    "        self.bn2    = norm_layer(width)\n",
    "        self.conv3  = conv1x1(width,out_planes * self.expansion)\n",
    "        self.bn3    = norm_layer(out_planes * self.expansion)\n",
    "        self.relu   = nn.ReLU()\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self,z):\n",
    "        identity    = z\n",
    "        \n",
    "        out         = self.conv1(z)\n",
    "        out         = self.bn1(out)\n",
    "        out         = self.relu(out)\n",
    "        \n",
    "        out         = self.conv2(out)\n",
    "        out         = self.bn2(out)\n",
    "        out         = self.relu(out)\n",
    "        \n",
    "        out         = self.conv3(out)\n",
    "        out         = self.bn3(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(z)\n",
    "        \n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Resnet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,block,layers,num_classes = 1000,zero_init_residual = False,\n",
    "                groups = 1,width_per_group = 64,replace_stride_with_dilation = None,\n",
    "                norm_layer = None):\n",
    "        \n",
    "        super(ResNet,self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        \n",
    "        self.in_planes = 64\n",
    "        self.dilation = 1\n",
    "        \n",
    "        if replace_stride_with_dilation is None:\n",
    "            # Each element in the tuple indicates if we should replace \n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False,False,False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"Invalid argument : Size error for replace_stride_with_dilation\")\n",
    "        \n",
    "        self.groups        = groups\n",
    "        self.base_width    = width_per_group\n",
    "        \n",
    "        self.conv1         = nn.Conv2d(3,self.in_planes,kernel_size = 7,stride = 2,padding = 3,\n",
    "                                      bias = False)\n",
    "        self.bn1           = norm_layer(self.in_planes)\n",
    "        self.relu          = nn.ReLU()\n",
    "        self.maxpool       = nn.MaxPool2d(kernel_size = 3,stride = 2,padding = 1)\n",
    "        self.layer1        = self._make_layer(block,64,layers[0])\n",
    "        self.layer2        = self._make_layer(block,128,layers[1],stride = 2,\n",
    "                                             dilate = replace_stride_with_dilation[0])\n",
    "        self.layer3        = self._make_layer(block,256,layers[2],stride = 2,\n",
    "                                             dilate = replace_stride_with_dilation[1])\n",
    "        self.layer4        = self._make_layer(block,512,layers[3],stride = 2,\n",
    "                                              dilate = replace_stride_with_dilation[2])\n",
    "        self.avgpool       = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc            = nn.Linear(512 * block.expansion,num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode = 'fan_out',nonlinearity = 'relu')\n",
    "            elif isinstance(m,(nn.BatchNorm2d,nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "                \n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m,Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight,0)\n",
    "                elif isinstance(m,BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight,0)\n",
    "        \n",
    "    def update_temperature(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,Dynamic_conv2d):\n",
    "                m.update_temperature()              ### ???\n",
    "    \n",
    "    def _make_layer(self,block,out_planes,blocks,stride = 1,dilate = False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        \n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.in_planes != out_planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                            conv1x1(self.in_planes,out_planes * block.expansion,stride),\n",
    "                            norm_layer(out_planes * block.expansion),\n",
    "                            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_planes,out_planes,stride,downsample,self.groups,\n",
    "                           self.base_width,previous_dilation,norm_layer))\n",
    "        self.in_planes = out_planes * block.expansion\n",
    "        for _ in range(1,blocks):\n",
    "            layers.append(block(self.in_planes,out_planes,groups = self.groups,\n",
    "                               base_width = self.base_width,dilation = self.dilation,\n",
    "                               norm_layer = norm_layer))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _forward_impl(self,z):\n",
    "        print('1')\n",
    "        z = self.conv1(z)\n",
    "        z = self.bn1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.maxpool(z)\n",
    "        print('2')\n",
    "        z = self.layer1(z)\n",
    "        z = self.layer2(z)\n",
    "        z = self.layer3(z)\n",
    "        z = self.layer4(z)\n",
    "        \n",
    "        z = self.avgpool(z)\n",
    "        z = torch.flatten(z,1)\n",
    "        z = self.fc(z)\n",
    "        print('3')\n",
    "        \n",
    "        return z\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resnet(arch,block,layers,pretrained,progress, **kwargs):\n",
    "    model = ResNet(block,layers, **kwargs)\n",
    "    print(\"Hi\")\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],progress = progress)\n",
    "        model.load_state_dict(state_dict)       \n",
    "    return model\n",
    "def resnet18(pretrained = False,progress = True,**kwargs):\n",
    "    print(\"hey\")\n",
    "    return _resnet('resnet18',BasicBlock,[2,2,2,2],pretrained,progress,**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = resnet18(num_classes = classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rate    = 0.1\n",
    "momentum_ = 0.9\n",
    "w_decay   = 1e-4\n",
    "epochs    = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "classes = 10 \n",
    "trainset_cifar10 = torchvision.datasets.CIFAR10(root = '/home/varshittha/dynamic-convolution',train=True,\n",
    "                                                download=True,\n",
    "                                                transform=transforms.Compose([\n",
    "                                                transforms.Pad(4),\n",
    "                                                transforms.RandomCrop(32),\n",
    "                                                transforms.RandomHorizontalFlip(),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))\n",
    "                                            ]))\n",
    "trainloader_cifar10 = torch.utils.data.DataLoader(trainset_cifar10, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "testset_cifar10 = torchvision.datasets.CIFAR10(root='/home/varshittha/dynamic-convolution', train=False, download=True,\n",
    "                                           transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                           ]))\n",
    "testloader_cifar10 = torch.utils.data.DataLoader(testset_cifar10, batch_size=20, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n",
      "Hi\n"
     ]
    }
   ],
   "source": [
    "net = resnet18(num_classes = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(),lr = l_rate,momentum = momentum_,weight_decay = w_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lr(optimizer,epoch):\n",
    "    if epoch in [epochs * 0.5,epochs * 0.75,epochs * 0.85]:\n",
    "        for p in optimizer.param_groups:\n",
    "            p['lr'] *= 0.1\n",
    "            l_rate   = p['lr']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('xxx')\n",
    "    net.train()\n",
    "    print('yyy')\n",
    "    avg_loss = 0.\n",
    "    train_acc = 0.\n",
    "    update_lr(optimizer, epoch)\n",
    "    print(l_rate)\n",
    "    for batch_idx, (data, target) in enumerate(trainloader_cifar10):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        output.to(device)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        avg_loss += loss.item()\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        train_acc += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    print('Train Epoch: {}, loss{:.6f}, acc{}'.format(epoch, loss.item(), train_acc/len(trainloader_cifar10 .dataset)), end='')\n",
    "    \n",
    "    net.update_temperature()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    net.eval()\n",
    "    test_loss = 0.\n",
    "    correct=0.\n",
    "    with torch.no_grad():\n",
    "        for data, label in testloader_cifar10:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            print(data.size())\n",
    "            output = net(data)\n",
    "            output.to(device)\n",
    "            test_loss += F.cross_entropy(output, label, size_average=False).item()\n",
    "            pred =  output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n",
    "    test_loss/=len(testloader_cifar10.dataset)\n",
    "    correct = int(correct)\n",
    "    print('Test set:average loss: {:.4f}, accuracy{}'.format(test_loss, 100.*correct/len(testloader_cifar10.dataset)))\n",
    "    return correct/len(testloader_cifar10.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "xxx\n",
      "yyy\n",
      "0.1\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-eb365c3ca219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'I came'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtemp_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-1389c04ef693>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_acc=0.\n",
    "for i in range(epochs):\n",
    "    print(i)\n",
    "    train(i+1)\n",
    "    print('I came')\n",
    "    temp_acc = val(i+1)\n",
    "    if temp_acc>best_val_acc:\n",
    "        best_val_acc = temp_acc\n",
    "print('Best acc{}'.format(best_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
