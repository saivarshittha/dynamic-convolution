{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import os \n",
    "import pandas as pd\n",
    "from torchvision.datasets.folder import default_loader\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from collections import OrderedDict\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention1d(nn.Module):\n",
    "    def __init__(self,in_planes,ratios,K,temperature,init_weight = True):\n",
    "        super(attention1d,self).__init__()\n",
    "        assert temperature % 3 == 1 # for reducing τ temperature from 30 to 1 linearly in the first 10 epochs.\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        if in_planes != 3:\n",
    "            hidden_planes = int(in_planes * ratios) + 1\n",
    "        else:\n",
    "            hidden_planes = K\n",
    "        \n",
    "        self.fc1   = nn.Conv1d(in_planes,hidden_planes,1,bias = False)\n",
    "        self.relu  = nn.RELU(inplace = True)\n",
    "        self.fc2   = nn.Conv1d(hidden_planes,K,1,bias = True)\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            \n",
    "            if isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "    \n",
    "    def update__temperature(self):\n",
    "        if self.temperature != 1:\n",
    "            self.temperature -= 3\n",
    "    \n",
    "    def forward(self,z):\n",
    "        z = self.avgpool(z)\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.fc2(z)\n",
    "        z = z.view(z.size(0),-1)   \n",
    "        return F.softmax(z/self.temperature,1) \n",
    "    \n",
    "class Dynamic_conv1d(nn.Module):\n",
    "    def __init__(self,in_planes,out_planes,kernel_size,ratio = 0.25,stride = 1,padding = 0,dilation = 1,groups = 1,bias = True,K = 4,temperature = 34,init_weight = True):\n",
    "        super(Dynamic_conv1d,self).__init__()\n",
    "        \n",
    "        if in_planes%groups != 0:\n",
    "            raise ValueError('Error : in_planes%groups != 0')\n",
    "        self.in_planes    = in_planes\n",
    "        self.out_planes   = out_planes\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.stride       = stride\n",
    "        self.padding      = padding\n",
    "        self.dilation     = dilation\n",
    "        self.groups       = groups\n",
    "        self.bias         = bias\n",
    "        self.K            = K\n",
    "        self.attention    = attention1d(in_planes,ratio,K,temperature)\n",
    "        self.weight       = nn.Parameter(torch.randn(K,out_planes,in_planes//groups,kernel_size),requires_grad = True)\n",
    "        \n",
    "        if bias :\n",
    "            self.bias = nn.Parameter(torch.Tensor(K,out_planes))\n",
    "        else:\n",
    "            self.bias = None\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for i in range(self.K):\n",
    "            nn.init.kaiming_uniform_(self.weight[i])\n",
    "    def update_temperature(self):\n",
    "        self.attention.update__temperature()\n",
    "    \n",
    "    def forward(self,z):\n",
    "        \n",
    "#         Regard batch as a dimensional variable, perform group convolution,\n",
    "#         because the weight of group convolution is different, \n",
    "#         and the weight of dynamic convolution is also different\n",
    "        softmax_attention = self.attention(z)\n",
    "        batch_size ,in_planes,height = z.size()\n",
    "        z = z.view(1,-1,height,) # changing into dimension for group convolution\n",
    "        weight = self.weight.view(self.K,-1)\n",
    "        \n",
    "#         The generation of the weight of dynamic convolution,\n",
    "#         which generates batch_size convolution parameters \n",
    "#         (each parameter is different) \n",
    "        aggregate_weight = torch.mm(softmax_attention,self.bias).view(-1,self.in_planes,self.kernel_size,)# expects two matrices (2D tensors)\n",
    "        if self.bias is not None:\n",
    "            aggregate_bias = torch.mm(softmax_attention,self.bias).view(-1)\n",
    "            output = F.conv1d(x,weight = aggregate_weight,bias = aggregate_bias,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        else:\n",
    "            output = F.conv1d(x,weight = aggregate_weight,bias = None,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        output = output.view(batch_size, self.out_planes, output.size(-1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention2d(nn.Module):\n",
    "    def __init__(self,in_planes,ratios,K,temperature,init_weight = True):\n",
    "        super(attention2d,self).__init__()\n",
    "        assert temperature % 3 == 1 # for reducing τ temperature from 30 to 1 linearly in the first 10 epochs.\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        if in_planes != 3:\n",
    "            hidden_planes = int(in_planes * ratios) + 1\n",
    "        else:\n",
    "            hidden_planes = K\n",
    "        \n",
    "        self.fc1   = nn.Conv2d(in_planes,hidden_planes,1,bias = False)\n",
    "        self.relu  = nn.RELU(inplace = True)\n",
    "        self.fc2   = nn.Conv2d(hidden_planes,K,1,bias = True)\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            \n",
    "            if isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "    \n",
    "    def update__temperature(self):\n",
    "        if self.temperature != 1:\n",
    "            self.temperature -= 3\n",
    "    \n",
    "    def forward(self,z):\n",
    "        z = self.avgpool(z)\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.fc2(z)\n",
    "        z = z.view(z.size(0),-1)   \n",
    "        return F.softmax(z/self.temperature,1) \n",
    "    \n",
    "class Dynamic_conv2d(nn.Module):\n",
    "    def __init__(self,in_planes,out_planes,kernel_size,ratio = 0.25,stride = 1,padding = 0,dilation = 1,groups = 1,bias = True,K = 4,temperature = 34,init_weight = True):\n",
    "        super(Dynamic_conv2d,self).__init__()\n",
    "        \n",
    "        if in_planes%groups != 0:\n",
    "            raise ValueError('Error : in_planes%groups != 0')\n",
    "        self.in_planes    = in_planes\n",
    "        self.out_planes   = out_planes\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.stride       = stride\n",
    "        self.padding      = padding\n",
    "        self.dilation     = dilation\n",
    "        self.groups       = groups\n",
    "        self.bias         = bias\n",
    "        self.K            = K\n",
    "        self.attention    = attention2d(in_planes,ratio,K,temperature)\n",
    "        self.weight       = nn.Parameter(torch.randn(K,out_planes,in_planes//groups,kernel_size,kernel_size),requires_grad = True)\n",
    "        \n",
    "        if bias :\n",
    "            self.bias = nn.Parameter(torch.Tensor(K,out_planes))\n",
    "        else:\n",
    "            self.bias = None\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for i in range(self.K):\n",
    "            nn.init.kaiming_uniform_(self.weight[i])\n",
    "    def update_temperature(self):\n",
    "        self.attention.update__temperature()\n",
    "    \n",
    "    def forward(self,z):\n",
    "        \n",
    "#         Regard batch as a dimensional variable, perform group convolution,\n",
    "#         because the weight of group convolution is different, \n",
    "#         and the weight of dynamic convolution is also different\n",
    "        softmax_attention = self.attention(z)\n",
    "        batch_size ,in_planes,height,width = z.size()\n",
    "        z = z.view(1,-1,height,width) # changing into dimension for group convolution\n",
    "        weight = self.weight.view(self.K,-1)\n",
    "        \n",
    "#         The generation of the weight of dynamic convolution,\n",
    "#         which generates batch_size convolution parameters \n",
    "#         (each parameter is different) \n",
    "        aggregate_weight = torch.mm(softmax_attention,self.bias).view(-1,self.in_planes,self.kernel_size,)# expects two matrices (2D tensors)\n",
    "        if self.bias is not None:\n",
    "            aggregate_bias = torch.mm(softmax_attention,self.bias).view(-1)\n",
    "            output = F.conv2d(x,weight = aggregate_weight,bias = aggregate_bias,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        else:\n",
    "            output = F.conv2d(x,weight = aggregate_weight,bias = None,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        output = output.view(batch_size, self.out_planes, output.size(-2),output.size(-1))\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention3d(nn.Module):\n",
    "    def __init__(self,in_planes,ratios,K,temperature,init_weight = True):\n",
    "        super(attention3d,self).__init__()\n",
    "        assert temperature % 3 == 1 # for reducing τ temperature from 30 to 1 linearly in the first 10 epochs.\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "        \n",
    "        if in_planes != 3:\n",
    "            hidden_planes = int(in_planes * ratios) + 1\n",
    "        else:\n",
    "            hidden_planes = K\n",
    "        \n",
    "        self.fc1   = nn.Conv3d(in_planes,hidden_planes,1,bias = False)\n",
    "        self.relu  = nn.RELU(inplace = True)\n",
    "        self.fc2   = nn.Conv3d(hidden_planes,K,1,bias = False)\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias,0)\n",
    "            \n",
    "            if isinstance(m,nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "    \n",
    "    def update__temperature(self):\n",
    "        if self.temperature != 1:\n",
    "            self.temperature -= 3\n",
    "    \n",
    "    def forward(self,z):\n",
    "        z = self.avgpool(z)\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.fc2(z)\n",
    "        z = z.view(z.size(0),-1)   \n",
    "        return F.softmax(z/self.temperature,1) \n",
    "    \n",
    "class Dynamic_conv3d(nn.Module):\n",
    "    def __init__(self,in_planes,out_planes,kernel_size,ratio = 0.25,stride = 1,padding = 0,dilation = 1,groups = 1,bias = True,K = 4,temperature = 34,init_weight = True):\n",
    "        super(Dynamic_conv2d,self).__init__()\n",
    "        \n",
    "        if in_planes%groups != 0:\n",
    "            raise ValueError('Error : in_planes%groups != 0')\n",
    "        self.in_planes    = in_planes\n",
    "        self.out_planes   = out_planes\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.stride       = stride\n",
    "        self.padding      = padding\n",
    "        self.dilation     = dilation\n",
    "        self.groups       = groups\n",
    "        self.bias         = bias\n",
    "        self.K            = K\n",
    "        self.attention    = attention3d(in_planes,ratio,K,temperature)\n",
    "        self.weight       = nn.Parameter(torch.randn(K,out_planes,in_planes//groups,kernel_size,kernel_size),requires_grad = True)\n",
    "        \n",
    "        if bias :\n",
    "            self.bias = nn.Parameter(torch.Tensor(K,out_planes))\n",
    "        else:\n",
    "            self.bias = None\n",
    "        if init_weight:\n",
    "            self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for i in range(self.K):\n",
    "            nn.init.kaiming_uniform_(self.weight[i])\n",
    "    def update_temperature(self):\n",
    "        self.attention.update__temperature()\n",
    "    \n",
    "    def forward(self,z):\n",
    "        \n",
    "#         Regard batch as a dimensional variable, perform group convolution,\n",
    "#         because the weight of group convolution is different, \n",
    "#         and the weight of dynamic convolution is also different\n",
    "        softmax_attention = self.attention(z)\n",
    "        batch_size ,in_planes,height,width = z.size()\n",
    "        z = z.view(1,-1,height,width) # changing into dimension for group convolution\n",
    "        weight = self.weight.view(self.K,-1)\n",
    "        \n",
    "#         The generation of the weight of dynamic convolution,\n",
    "#         which generates batch_size convolution parameters \n",
    "#         (each parameter is different) \n",
    "        aggregate_weight = torch.mm(softmax_attention,self.bias).view(-1,self.in_planes,self.kernel_size,self.kernel_size,self.kernel_size)# expects two matrices (2D tensors)\n",
    "        if self.bias is not None:\n",
    "            aggregate_bias = torch.mm(softmax_attention,self.bias).view(-1)\n",
    "            output = F.conv3d(x,weight = aggregate_weight,bias = aggregate_bias,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        else:\n",
    "            output = F.conv3d(x,weight = aggregate_weight,bias = None,stride = self.stride,padding = self.padding,\n",
    "                             dilation=self.dilation, groups=self.groups * batch_size)\n",
    "        output = output.view(batch_size, self.out_planes,output.size(-3),output.size(-2),output.size(-1))\n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "classes = 10 \n",
    "trainset_cifar10 = torchvision.datasets.CIFAR10(root = '/home/varshittha/dynamic-convolution',train=True,\n",
    "                                                download=True,\n",
    "                                                transform=transforms.Compose([\n",
    "                                                transforms.Pad(4),\n",
    "                                                transforms.RandomCrop(32),\n",
    "                                                transforms.RandomHorizontalFlip(),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))\n",
    "                                            ]))\n",
    "trainloader_cifar10 = torch.utils.data.DataLoader(trainset_cifar10, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "testset_cifar10 = torchvision.datasets.CIFAR10(root='/home/varshittha/dynamic-convolution', train=False, download=True,\n",
    "                                           transform=transforms.Compose([\n",
    "                                               transforms.ToTensor(),\n",
    "                                               transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                           ]))\n",
    "testloader_cifar10 = torch.utils.data.DataLoader(testset_cifar10, batch_size=128, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dy_resnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### conv1x1 - dynamic convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_planes,out_planes,stride = 1): \n",
    "    return Dynamic_conv2d(in_planes,out_planes,kernel_size = 1,stride = stride,bias = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### conv3x3 - dynamic convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes,out_planes,stride = 1,groups = 1,dilation = 1): # conv3x3 for dynamic convolution\n",
    "    return Dynamic_conv2d(in_planes,out_planes,kernel_size = 3,stride = stride,padding = dilation,groups = groups,bias = False,dilation = dilation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module): # expansion = 1, dilation = 1 , base_width = 64 ,groups = 1\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self,in_planes,out_planes,stride = 1,downsample = None,\n",
    "                 groups = 1,base_width = 64,dilation = 1,norm_layer = None):\n",
    "        \n",
    "        super(BasicBlock,self).__init__()\n",
    "        \n",
    "        if base_width != 64:\n",
    "            raise ValueError('BasicBlock supports only base_width = 64')\n",
    "        if groups != 1: \n",
    "            raise ValueError('BasicBlock supports only groups = 1')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError('BasicBlock doesnot support dilation > 1')\n",
    "        # self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        \n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        \n",
    "        self.conv1 = conv3x3(in_planes,out_planes,stride)\n",
    "        self.bn1   = norm_layer(out_planes)\n",
    "        self.relu  = nn.RELU(inplace = True) # modify input directly.\n",
    "        self.conv2 = conv3x3(out_planes,out_planes)\n",
    "        self.bn2   = norm_layer(out_planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self , z):\n",
    "        \n",
    "        identity = z\n",
    "        \n",
    "        out = self.conv1(z)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(z)\n",
    "        \n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self,in_planes,out_planes,stride = 1,downsample = None,\n",
    "                groups = 1,base_width = 64,dilation = 1,norm_layer = None):\n",
    "        super(Bottleneck,self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        \n",
    "        width = int(out_planes *(base_width/64.)) * groups  ## ?? \n",
    "        \n",
    "        self.conv1  = conv1x1(in_planes,width)\n",
    "        self.bn1    = norm_layer(width)\n",
    "        self.conv2  = conv3x3(width,width,stride,groups,dilation)\n",
    "        self.bn2    = norm_layer(width)\n",
    "        self.conv3  = conv1x1(width,out_planes * self.expansion)\n",
    "        self.bn3    = norm_layer(out_planes * self.expansion)\n",
    "        self.relu   = nn.RELU(inplace = True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self,z):\n",
    "        identity    = z\n",
    "        \n",
    "        out         = self.conv1(z)\n",
    "        out         = self.bn1(out)\n",
    "        out         = self.relu(out)\n",
    "        \n",
    "        out         = self.conv2(out)\n",
    "        out         = self.bn2(out)\n",
    "        out         = self.relu(out)\n",
    "        \n",
    "        out         = self.conv3(out)\n",
    "        out         = self.bn3(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(z)\n",
    "        \n",
    "        out = out + identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Resnet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,block,layers,num_classes = 1000,zero_init_residual = False,\n",
    "                groups = 1,width_per_group = 64,replace_stride_with_dilation = None,\n",
    "                norm_layer = None):\n",
    "        \n",
    "        super(ResNet,self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self.norm_layer = norm_layer\n",
    "        \n",
    "        self.in_planes = 64\n",
    "        self.dilation = 1\n",
    "        \n",
    "        if replace_stride_with_dilation is None:\n",
    "            # Each element in the tuple indicates if we should replace \n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False,False,False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"Invalid argument : Size error for replace_stride_with_dilation\")\n",
    "        \n",
    "        self.groups        = groups\n",
    "        self.base_width    = width_per_group\n",
    "        \n",
    "        self.conv1         = nn.Conv2d(3,self.in_planes,kernel_size = 7,stride = 2,padding = 3,\n",
    "                                      bias = False)\n",
    "        self.bn1           = norm_layer(self.in_planes)\n",
    "        self.relu          = nn.RELU(inplace = True)\n",
    "        self.maxpool       = nn.MaxPool2d(kernel_size = 3,stride = 2,padding = 1)\n",
    "        self.layer1        = self._make_layer(block,64,layers[0])\n",
    "        self.layer2        = self._make_layer(block,128,layers[1],stride = 2,\n",
    "                                             dilate = replace_stride_with_dilation[0])\n",
    "        self.layer3        = self._make_layer(block,256,layers[2],stride = 2,\n",
    "                                             dilate = replace_stride_with_dilation[1])\n",
    "        self.layer4        = self._make_layer(block,512,layers[3],stride = 2,\n",
    "                                              dilate = replace_stride_with_dilation[2])\n",
    "        self.avgpool       = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc            = nn.Linear(512 * block.expansion,num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,mode = 'fan_out',nonlinearity = 'relu')\n",
    "            elif isinstance(m,(nn.BatchNorm2d,nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "                \n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m,Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight,0)\n",
    "                elif isinstance(m,BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight,0)\n",
    "        \n",
    "    def update_temperature(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,Dynamic_conv2d):\n",
    "                m.update_temperature()              ### ???\n",
    "    \n",
    "    def _make_layer(self,block,out_planes,blocks,stride = 1,dilate = False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        \n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.in_planes != out_planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                            conv1x1(self.in_planes,out_planes * block.expansion,stride),\n",
    "                            norm_layer(out_planes * block.expansion),\n",
    "                            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_planes,out_planes,stride,downsample,self.groups,\n",
    "                           self.base_width,previous_dilation,norm_layer))\n",
    "        self.in_planes = out_planes * block.expansion\n",
    "        for _ in range(1,blocks):\n",
    "            layers.append(block(self.in_planes,out_planes,groups = self.groups,\n",
    "                               base_width = self.base_width,dilation = self.dilation,\n",
    "                               norm_layer = norm_layer))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _forward_impl(self,z):\n",
    "        z = self.conv1(z)\n",
    "        z = self.bn1(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.maxpool(z)\n",
    "        \n",
    "        z = self.layer1(z)\n",
    "        z = self.layer2(z)\n",
    "        z = self.layer3(z)\n",
    "        z = self.layer4(z)\n",
    "        \n",
    "        z = self.avgpool(z)\n",
    "        z = torch.flatten(z,1)\n",
    "        z = self.fc(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "def _resnet(arch,block,layers,pretrained,progress, **kwargs):\n",
    "    model = ResNet(block,layers, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],progress = progress)\n",
    "        model.load_state_dict(state_dict)       \n",
    "    return model\n",
    "def resnet18(pretrained = False,progress = True,**kwargs):\n",
    "    return _resnet('resnet18',BasicBlock,[2,2,2,2],pretrained,progress,**kwargs)\n",
    "        \n",
    "            \n",
    "                            \n",
    "    \n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "                \n",
    "                \n",
    "                                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
